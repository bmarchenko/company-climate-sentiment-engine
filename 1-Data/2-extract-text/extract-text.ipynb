{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "from boilerpipe.extract import Extractor\n",
    "from urllib.parse import urlparse\n",
    "from langdetect import detect\n",
    "LINKS_DIR = \"../1-scrape-google-links/output\"\n",
    "OUT_DIR = \"extracted_texts\"\n",
    "if not os.path.exists(OUT_DIR):\n",
    "    os.mkdir(OUT_DIR)\n",
    "MIN_TEXT_LENGTH = 1300\n",
    "STOP_SITES = (\"twitter.com\", \"facebook.com\", \"youtube.com\", \"wikipedia\", \"slideshare.net\", \".pdf\", \"slideplayer.com\", \"cdp.net\", \"video\", \"nationalgeographic.com\", \"sourcewatch.org\", \"wikimedia\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextExtractor():\n",
    "    def __init__(self, company, df, spamwriter, *args, **kwargs):\n",
    "        self.company = company\n",
    "        self.spamwriter = spamwriter\n",
    "        self.df = df\n",
    "    \n",
    "    def is_url_ok(self, url):\n",
    "        parsed_url = urlparse(url)\n",
    "        if any(word in url for word in STOP_SITES):\n",
    "            print(\"Skipping due to stop website: {}\".format(url))\n",
    "            return False\n",
    "        elif any([name.lower() in parsed_url.netloc for name in company.split()]):\n",
    "            print(\"Skipping due to company's website: {} in {}\".format(self.company, url))\n",
    "            return False\n",
    "        elif parsed_url.path in [\"\", \"/\", '/en/', '/en']:\n",
    "            print(\"Skipping due to front page {}\".format(url))\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def is_text_ok(self, text):\n",
    "        if detect(text) != \"en\":\n",
    "            print(\"Skipping: Extracted text not English: {}\".format(text))\n",
    "            return False\n",
    "        elif len(text) < MIN_TEXT_LENGTH:\n",
    "            print(\"Skipping: Extracted text is too short\")\n",
    "            return False\n",
    "#         elif self.company not in text:\n",
    "#             print(\"Skipping: No company name in Extracted text: {}\".format(self.company))\n",
    "#             return False\n",
    "        return True\n",
    "\n",
    "    def highlight_kewords(self, text):\n",
    "        return re.sub('(climate policy|climate change|innovation|climate|pollution|sustainable|devastation|CO2|CO\\(2\\)|carbon|{})'.format(self.company), r'<mark>\\1</mark>', text, flags=re.IGNORECASE)\n",
    "\n",
    "    def extract_file_data(self):\n",
    "        data = []\n",
    "        for index, row in self.df.iterrows():\n",
    "            url = row[\"url\"]\n",
    "            if not self.is_url_ok(url):\n",
    "                continue\n",
    "            print(url)\n",
    "            try:\n",
    "                extractor = Extractor(extractor='ArticleExtractor', url=url)\n",
    "                extracted_text = extractor.getHTML()\n",
    "                if self.is_text_ok(extracted_text):\n",
    "                    spamwriter.writerow((company, url, row.get(\"title\", \"\"), row.get(\"text\", \"\"), self.highlight_kewords(extracted_text)))\n",
    "            except Exception as ex:\n",
    "                print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel\n",
      "Extracting Intel\n",
      "Skipping due to company's website: Intel in https://www.intel.com/content/www/us/en/corporate-responsibility/environment-climate-change-policy.html\n",
      "Skipping due to stop website: https://www.nytimes.com/video/climate/100000005588339/intel-makes-case-for-the-paris-agreement.html\n",
      "Skipping due to company's website: Intel in https://www.intel.com/content/www/us/en/corporate-responsibility/intel-climate-change-pledge.html\n",
      "Skipping due to company's website: Intel in https://jupiterintel.com/\n",
      "Skipping due to stop website: https://www.intel.com/content/dam/www/public/us/en/documents/corporate-information/environment-climate-change-policy.pdf\n",
      "https://www.japantimes.co.jp/news/2018/02/14/world/politics-diplomacy-world/u-s-intel-chief-deviates-trump-denial-warns-climate-change-potential-upheaval/\n",
      "Skipping due to company's website: Intel in https://www.intel.com/content/www/us/en/technology-innovation/polar-bears-climate-change.html\n",
      "https://www.defenseone.com/threats/2016/09/pentagon-continues-beat-climate-change-drum/131384/\n",
      "https://www.theinquirer.net/inquirer/news/3011437/apple-intel-microsoft-and-more-commit-to-paris-agreement-on-climate-change\n",
      "https://phys.org/news/2018-02-intel-chief-issues-climate.html\n",
      "Skipping due to stop website: http://download.intel.com/pressroom/pdf/CDsvsdownloadsrelease.pdf\n",
      "https://www.wired.com/2008/06/we-judge-global/\n",
      "https://www.usatoday.com/story/news/politics/2016/09/21/obama-orders-intelligence-agencies-study-climate-change/90799356/\n",
      "https://venturebeat.com/2017/06/01/intel-predicts-autonomous-cars-will-spawn-a-passenger-economy/\n",
      "https://www.politico.com/story/2017/06/01/trump-climate-tech-ceos-239039\n",
      "http://fortune.com/2017/06/01/paris-climate-agreement-business-leaders-react/\n",
      "https://www.ft.com/content/5f2b6e06-4663-11e7-8519-9f94ee97d996\n",
      "https://insideclimatenews.org/news/13022018/climate-change-conflict-disasters-worldwide-threat-assessment-intelligence-agencies-refugees\n",
      "https://www.irishbuildingmagazine.ie/2017/11/20/intel-goes-100-renewable-to-power-360-acre-leixlip-campus/\n",
      "Skipping due to stop website: https://www.cnbc.com/video/2017/06/01/intel-ceo-we-need-to-engage-in-paris-climate-accord.html\n",
      "http://www.chicagotribune.com/business/ct-paris-climate-change-ceo-reaction-20170602-story.html\n",
      "https://www.washingtonpost.com/news/capital-weather-gang/wp/2018/04/09/how-a-small-start-up-firm-wants-to-revitalize-climate-change-research/\n",
      "https://mashable.com/2017/05/11/trump-intel-report-cites-climate-change-risks/\n",
      "https://www.greenbiz.com/article/alphabet-intel-and-walmart-low-carbon-products-make-business-sense\n",
      "https://www.engadget.com/2017/06/01/apple-microsoft-google-facebook-paris-agreement-letter/\n",
      "https://www.pcgamesn.com/intel-stock-ipac-political-donations\n",
      "https://mashable.com/2017/12/18/trump-national-security-strategy-omits-climate-change-threat/\n",
      "https://www.washingtonpost.com/news/capital-weather-gang/wp/2018/02/12/climate-change-could-put-businesses-underwater-start-up-firm-jupiter-aims-to-come-to-the-rescue/\n",
      "Skipping due to stop website: http://www.handprint.in/pdf/environment-climate-change-policy-harper.pdf\n",
      "http://www.thejakartapost.com/news/2018/02/14/us-intel-chief-issues-warning-about-climate-change.html\n",
      "I\n",
      "Extracting I\n",
      "Skipping due to company's website: I in https://university.crs.org/climate-change\n",
      "Skipping due to company's website: I in https://climate.nasa.gov/\n",
      "Skipping due to stop website: https://en.wikipedia.org/wiki/Climate_change\n",
      "Skipping due to company's website: I in https://climate.nasa.gov/evidence\n",
      "Skipping due to company's website: I in https://www.resilientoahu.org/about-the-commission/\n",
      "https://www.bloomberg.com/climate-changed\n",
      "Skipping due to company's website: I in http://www.ipcc.ch/report/ar5/wg1/\n",
      "https://www.cnn.com/2018/05/08/health/climate-change-children-pediatrics-study/index.html\n",
      "Skipping due to stop website: https://www.nationalgeographic.com/environment/climate-change/\n",
      "http://www.takepart.com/flashcards/what-is-climate-change/index.html\n"
     ]
    }
   ],
   "source": [
    "links_number = 0\n",
    "for company in os.listdir(LINKS_DIR):\n",
    "#     if company == \"PetroChina\":\n",
    "    if os.path.exists(\"{}/{}.csv\".format(OUT_DIR, company)):\n",
    "        continue\n",
    "    with open(\"{}/{}.csv\".format(OUT_DIR, company), \"w\") as f:\n",
    "        spamwriter = csv.writer(f)\n",
    "        spamwriter.writerow([\"company\", \"url\", \"title\", \"extract\", \"content\"])\n",
    "        print(company)\n",
    "        if os.path.isfile(LINKS_DIR+\"/\"+company):\n",
    "            continue\n",
    "        print(\"Extracting {}\".format(company))\n",
    "        for fl in os.listdir(\"{}/{}\".format(LINKS_DIR, company)):\n",
    "            if fl.endswith(\".csv\"):\n",
    "                df = pd.read_csv(\"{}/{}/{}\".format(LINKS_DIR, company, fl))\n",
    "                links_number += len(df)\n",
    "                TextExtractor(company, df, spamwriter).extract_file_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../../2-Baseline/no_text.csv\")\n",
    "# texts = []\n",
    "# for num, row in df.iterrows():\n",
    "#     print(num)\n",
    "#     texts.append(Extractor(extractor='ArticleExtractor', url=row['url']).getHTML())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = pd.read_csv(\"../3-annotation/MTurkBatchesResults/truth.csv\")\n",
    "# for num, row in df.iterrows():\n",
    "# #     print( row['url'])\n",
    "#     row2 = df2.loc[df2[''] == row['url']]\n",
    "#     print(len(row['content']))\n",
    "# pd.merge(df, df2, on='url', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY: Extracted texts of 10 articles out of 0 links\n",
      "MOST POPULAR SOURCES: netloc\n",
      "www.triplem.com.au          1\n",
      "www.nexans.com              1\n",
      "www.marymattingly.com       1\n",
      "www.jobsinberlin.eu         1\n",
      "www.bath.ac.uk              1\n",
      "wamgroup.com                1\n",
      "plq.org                     1\n",
      "globalwarming-facts.info    1\n",
      "en.wiktionary.org           1\n",
      "eie.academia.edu            1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(OUT_FILE_NAME)\n",
    "print(\"SUMMARY: Extracted texts of {} articles out of {} links\".format(len(df), links_number))\n",
    "df[\"netloc\"] =  df.apply(lambda row: urlparse(row.url).netloc,axis=1)\n",
    "print(\"MOST POPULAR SOURCES: {}\".format(df.groupby(\"netloc\").size().sort_values(ascending=False, inplace=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment",
   "language": "python",
   "name": "sentiment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
